import subprocess
import requests
import re
import os
import sys
import time
import signal
import platform
import json
from typing import List, Dict, Any, Optional, Union

# Configuration
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODELS_URL = "http://localhost:11434/api/tags"
DEFAULT_MODEL = "deepseek-r1:1.5b"
CONFIG_DIR = os.path.expanduser("~/.config/ollama-terminal")
CONFIG_FILE = os.path.join(CONFIG_DIR, "config.txt")
HISTORY_FILE = os.path.join(CONFIG_DIR, "history.txt")
MAX_HISTORY = 100
MODEL_START_TIMEOUT = 200  # D√©lai d'attente maximum pour le d√©marrage du mod√®le (en secondes)

class OllamaTerminal:
    def __init__(self):
        self.model = self._load_model_preference()
        self.history = self._load_history()
        self._setup_signal_handlers()
        self._ensure_server_running()
        self._ensure_model_available()
        
    def _load_model_preference(self) -> str:
        """Charge le mod√®le pr√©f√©r√© depuis le fichier de configuration ou utilise la valeur par d√©faut."""
        if not os.path.exists(CONFIG_DIR):
            os.makedirs(CONFIG_DIR, exist_ok=True)
        
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, "r") as f:
                    return f.read().strip() or DEFAULT_MODEL
            except Exception:
                return DEFAULT_MODEL
        else:
            with open(CONFIG_FILE, "w") as f:
                f.write(DEFAULT_MODEL)
            return DEFAULT_MODEL
    
    def _save_model_preference(self) -> None:
        """Sauvegarde le mod√®le pr√©f√©r√© dans le fichier de configuration."""
        with open(CONFIG_FILE, "w") as f:
            f.write(self.model)
    
    def _load_history(self) -> List[str]:
        """Charge l'historique des commandes."""
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, "r") as f:
                    return [line.strip() for line in f.readlines()[-MAX_HISTORY:]]
            except Exception:
                return []
        return []
    
    def _save_history(self, command: str) -> None:
        """Ajoute une commande √† l'historique et sauvegarde."""
        if command and command not in self.history:
            self.history.append(command)
            if len(self.history) > MAX_HISTORY:
                self.history = self.history[-MAX_HISTORY:]
            
            with open(HISTORY_FILE, "a") as f:
                f.write(f"{command}\n")
    
    def _setup_signal_handlers(self) -> None:
        """Configure les gestionnaires de signaux pour une sortie propre."""
        signal.signal(signal.SIGINT, self._handle_exit)
        signal.signal(signal.SIGTERM, self._handle_exit)
    
    def _handle_exit(self, sig, frame) -> None:
        """G√®re la sortie propre du programme."""
        print("\n\nFermeture en cours... Merci d'avoir utilis√© Ollama Terminal!")
        sys.exit(0)
    
    def _ensure_server_running(self) -> bool:
        """
        V√©rifie si le serveur Ollama est en cours d'ex√©cution.
        Si ce n'est pas le cas, tente de le d√©marrer.
        """
        try:
            requests.get("http://localhost:11434", timeout=2)
            return True
        except requests.exceptions.ConnectionError:
            print("Le serveur Ollama n'est pas en cours d'ex√©cution. Tentative de d√©marrage...")
            
            if platform.system() == "Windows":
                # Windows - utiliser start pour d√©marrer en arri√®re-plan
                subprocess.Popen("start ollama serve", shell=True)
            else:
                # Linux/Mac - d√©marrer en arri√®re-plan
                subprocess.Popen("ollama serve &", shell=True)
            
            # Attendre que le serveur d√©marre
            for _ in range(10):  # 10 tentatives, 1 seconde d'intervalle
                time.sleep(1)
                try:
                    requests.get("http://localhost:11434", timeout=2)
                    print("Le serveur Ollama a √©t√© d√©marr√© avec succ√®s.")
                    return True
                except requests.exceptions.ConnectionError:
                    pass
            
            print("Impossible de d√©marrer le serveur Ollama. Veuillez le d√©marrer manuellement.")
            return False
    
    def _ensure_model_available(self) -> bool:
        """
        V√©rifie si le mod√®le s√©lectionn√© est disponible.
        Si ce n'est pas le cas, tente de le t√©l√©charger.
        """
        try:
            response = requests.get(OLLAMA_MODELS_URL, timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model.get("name") for model in models]
                
                if self.model in model_names:
                    return True
                else:
                    print(f"Le mod√®le '{self.model}' n'est pas disponible. Tentative de t√©l√©chargement...")
                    return self._pull_model(self.model)
            
            return False
        except requests.exceptions.ConnectionError:
            print("Le serveur Ollama n'est pas accessible.")
            return False
    
    def _pull_model(self, model_name: str) -> bool:
        """
        T√©l√©charge le mod√®le sp√©cifi√©.
        """
        try:
            print(f"T√©l√©chargement du mod√®le '{model_name}'. Cela peut prendre un certain temps...")
            
            if platform.system() == "Windows":
                process = subprocess.Popen(f"ollama pull {model_name}", shell=True)
            else:
                process = subprocess.Popen(f"ollama pull {model_name}", shell=True)
            
            # Attendre que le processus termine avec un timeout
            start_time = time.time()
            while process.poll() is None:
                if time.time() - start_time > MODEL_START_TIMEOUT:
                    process.kill()
                    print(f"Le t√©l√©chargement du mod√®le a d√©pass√© le d√©lai de {MODEL_START_TIMEOUT} secondes.")
                    return False
                time.sleep(1)
            
            if process.returncode == 0:
                print(f"Le mod√®le '{model_name}' a √©t√© t√©l√©charg√© avec succ√®s.")
                return True
            else:
                print(f"√âchec du t√©l√©chargement du mod√®le '{model_name}'.")
                return False
                
        except Exception as e:
            print(f"Erreur lors du t√©l√©chargement du mod√®le: {e}")
            return False
    
    def ask_ollama(self, prompt: str, with_context: List[Dict] = None) -> str:
        """
        Envoie une requ√™te au serveur Ollama et retourne la r√©ponse.
        Supporte le contexte de conversation pour une meilleure continuit√©.
        """
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        
        # Ajouter le contexte s'il est fourni
        if with_context:
            payload["context"] = with_context
        
        try:
            print(f"Interrogation du mod√®le {self.model}...", end="", flush=True)
            start_time = time.time()
            
            response = requests.post(OLLAMA_URL, json=payload, timeout=60)
            response.raise_for_status()
            
            elapsed_time = time.time() - start_time
            print(f" Termin√© ({elapsed_time:.2f}s)")
            
            result = response.json()
            return result.get("response", "").strip(), result.get("context", None)
        except requests.exceptions.ConnectionError:
            print("\nErreur: Impossible de se connecter au serveur Ollama. Assurez-vous qu'il est en cours d'ex√©cution.")
            return "", None
        except requests.exceptions.Timeout:
            print("\nErreur: La requ√™te a expir√©. Le mod√®le prend trop de temps √† r√©pondre.")
            return "", None
        except requests.exceptions.RequestException as e:
            print(f"\nErreur lors de la requ√™te √† Ollama: {e}")
            return "", None
    
    def run_shell_command(self, command: str) -> subprocess.CompletedProcess:
        """Ex√©cute une commande shell et retourne le r√©sultat."""
        try:
            print(f"\n‚Üí Ex√©cution: {command}")
            # Utiliser shell=False est plus s√©curis√© quand c'est possible
            result = subprocess.run(
                command, 
                shell=True,  # On garde shell=True car on ex√©cute des commandes complexes
                capture_output=True, 
                text=True,
                timeout=300  # Timeout de 5 minutes
            )
            
            if result.stdout:
                print("=== Sortie ===")
                print(result.stdout)
            
            if result.stderr:
                print("=== Erreurs ===")
                print(result.stderr)
            
            return result
        except subprocess.TimeoutExpired:
            print("Erreur: La commande a d√©pass√© le d√©lai maximum d'ex√©cution (5 minutes).")
            return None
        except Exception as e:
            print(f"Erreur lors de l'ex√©cution de la commande: {e}")
            return None
    
    def clean_command_output(self, raw_output: str) -> List[str]:
        """Nettoie la sortie brute pour en extraire des commandes valides."""
        # S√©paration des lignes et nettoyage basique
        lines = [line.strip() for line in raw_output.split("\n") if line.strip()]
        
        # Filtre les lignes qui ne sont pas des commandes valides
        cleaned_lines = []
        for line in lines:
            # Ignorer les lignes vides, commentaires, ou blocs markdown
            if not line or line.startswith("#") or line.startswith("```"):
                continue
            
            # Supprimer les num√©ros de liste et les guillemets
            line = re.sub(r"^\d+[\.\)]\s*", "", line)
            
            # Nettoyage des guillemets et backticks
            if line.startswith("`") and line.endswith("`"):
                line = line[1:-1]
            elif line.count("`") % 2 == 0:
                line = line.replace("`", "")
            
            # Gestion des guillemets d√©s√©quilibr√©s
            if line.count('"') % 2 != 0:
                line = line.replace('"', '')
            if line.count("'") % 2 != 0:
                line = line.replace("'", "")
            
            # V√©rifier si la ligne ressemble √† une commande bash valide
            if not (line.startswith("```") or line.endswith("```")):
                cleaned_lines.append(line)
        
        return cleaned_lines
    
    def show_info(self) -> None:
        """Affiche les informations syst√®me et de configuration."""
        print("\n=== Informations sur Ollama Terminal ===")
        print(f"Syst√®me d'exploitation: {platform.system()} {platform.release()}")
        print(f"Python version: {platform.python_version()}")
        print(f"Mod√®le Ollama actuel: {self.model}")
        
        # V√©rifier si Ollama est en cours d'ex√©cution
        try:
            requests.get(OLLAMA_URL.replace("/api/generate", ""), timeout=2)
            print("Statut du serveur Ollama: En cours d'ex√©cution")
        except:
            print("Statut du serveur Ollama: Non disponible")
        
        # Liste des mod√®les disponibles
        try:
            response = requests.get(OLLAMA_MODELS_URL, timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                if models:
                    print("\nMod√®les disponibles:")
                    for model in models:
                        name = model.get('name')
                        size = model.get('size', 0) / (1024 * 1024 * 1024)  # Convertir en GB
                        print(f" - {name} ({size:.2f} GB)")
        except:
            pass
        
        print("\nRaccourcis clavier:")
        print(" - Ctrl+C: Quitter le programme")
        print(" - !info: Afficher ces informations")
        print(" - !model <nom>: Changer de mod√®le")
        print(" - !history: Afficher l'historique des commandes")
        print(" - !exit: Quitter le programme")
        print(" - !exec <commande>: Ex√©cuter directement une commande shell")
    
    def show_history(self) -> None:
        """Affiche l'historique des commandes."""
        if not self.history:
            print("L'historique est vide.")
            return
        
        print("\n=== Historique des commandes ===")
        for i, cmd in enumerate(self.history[-20:], 1):  # Afficher les 20 derni√®res commandes
            print(f"{i}. {cmd}")
    
    def change_model(self, model_name: str) -> None:
        """Change le mod√®le Ollama utilis√©."""
        if not model_name:
            print(f"Mod√®le actuel: {self.model}")
            return
        
        # V√©rifier si le mod√®le existe, sinon tenter de le t√©l√©charger
        try:
            response = requests.get(OLLAMA_MODELS_URL, timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model.get("name") for model in models]
                
                if model_name not in model_names:
                    print(f"Le mod√®le '{model_name}' n'est pas disponible. Tentative de t√©l√©chargement...")
                    if not self._pull_model(model_name):
                        print(f"Impossible d'utiliser le mod√®le '{model_name}'. Le mod√®le '{self.model}' est conserv√©.")
                        return
        except Exception as e:
            print(f"Erreur lors de la v√©rification du mod√®le: {e}")
            return
        
        # Changer le mod√®le
        self.model = model_name
        self._save_model_preference()
        print(f"Mod√®le chang√© pour: {self.model}")
    
    def select_commands(self, commands: List[str]) -> List[str]:
        """Permet √† l'utilisateur de s√©lectionner les commandes √† ex√©cuter."""
        if not commands:
            return []
        
        if len(commands) == 1:
            confirm = input(f"\nEx√©cuter cette commande ? \n[{commands[0]}] (oui/non/√©diter) : ").lower()
            if confirm in ("√©diter", "editer", "edit", "e"):
                edited_cmd = input(f"√âditer la commande : [{commands[0]}] > ")
                return [edited_cmd if edited_cmd.strip() else commands[0]]
            return commands if confirm in ("oui", "o", "yes", "y") else []
        
        print("\n=== Commandes disponibles ===")
        for i, cmd in enumerate(commands, 1):
            print(f"{i}. {cmd}")
        
        print("\nOptions:")
        print("- Entrez le num√©ro d'une commande pour l'ex√©cuter (ex: '2')")
        print("- Entrez plusieurs num√©ros s√©par√©s par des espaces (ex: '1 3')")
        print("- Entrez 'all' ou '*' pour toutes les ex√©cuter")
        print("- Entrez 'none' ou '0' pour n'en ex√©cuter aucune")
        print("- Entrez 'e:X' pour √©diter la commande num√©ro X")
        
        while True:
            choice = input("\nVotre choix : ").strip().lower()
            
            if choice in ("none", "0", "n", "non", "no"):
                return []
            
            if choice in ("all", "*", "a", "tout"):
                return commands
            
            # Mode √©dition
            if choice.startswith("e:") or choice.startswith("√©diter:") or choice.startswith("editer:"):
                try:
                    parts = choice.split(":", 1)
                    if len(parts) < 2:
                        print("Format incorrect. Utilisez 'e:X' o√π X est le num√©ro de la commande.")
                        continue
                    
                    idx = int(parts[1])
                    if 1 <= idx <= len(commands):
                        original_cmd = commands[idx-1]
                        edited_cmd = input(f"√âditer la commande : [{original_cmd}] > ")
                        if edited_cmd.strip():
                            commands[idx-1] = edited_cmd
                            print(f"Commande {idx} mise √† jour.")
                        continue
                    else:
                        print(f"Erreur: Le num√©ro {idx} est hors limites.")
                        continue
                except ValueError:
                    print("Num√©ro de commande invalide.")
                    continue
            
            try:
                # Traiter les num√©ros s√©par√©s par des espaces
                indices = [int(x) for x in choice.split()]
                selected = []
                
                for idx in indices:
                    if 1 <= idx <= len(commands):
                        selected.append(commands[idx-1])
                    else:
                        print(f"Erreur: Le num√©ro {idx} est hors limites.")
                
                if selected:
                    print("\nCommandes s√©lectionn√©es:")
                    for cmd in selected:
                        print(f"- {cmd}")
                    confirm = input("\nConfirmer l'ex√©cution ? (oui/non) : ").lower()
                    if confirm in ("oui", "o", "yes", "y"):
                        return selected
                
                return []
                
            except ValueError:
                # Si une seule valeur est entr√©e
                try:
                    idx = int(choice)
                    if 1 <= idx <= len(commands):
                        selected = commands[idx-1]
                        confirm = input(f"\nConfirmer l'ex√©cution de : \n[{selected}] (oui/non/√©diter) : ").lower()
                        if confirm in ("√©diter", "editer", "edit", "e"):
                            edited_cmd = input(f"√âditer la commande : [{selected}] > ")
                            return [edited_cmd if edited_cmd.strip() else selected]
                        return [selected] if confirm in ("oui", "o", "yes", "y") else []
                    else:
                        print(f"Erreur: Le num√©ro {idx} est hors limites.")
                except ValueError:
                    print("Entr√©e invalide. Veuillez utiliser les options propos√©es.")
    
    def exec_direct_command(self, command: str) -> None:
        """Ex√©cute directement une commande shell."""
        if not command:
            print("Aucune commande sp√©cifi√©e.")
            return
        
        self._save_history(command)
        self.run_shell_command(command)
    
    def get_system_info(self) -> str:
        """R√©cup√®re les informations syst√®me pour le contexte."""
        osname = platform.system()
        release = platform.release()
        if osname == "Linux":
            try:
                distro = subprocess.check_output("cat /etc/os-release | grep PRETTY_NAME", shell=True, text=True)
                distro = distro.split("=")[1].strip().strip('"')
            except:
                distro = "Linux"
            return f"{distro} {release}"
        return f"{osname} {release}"
    
    def main(self) -> None:
        """Fonction principale du programme."""
        print(f"=== Ollama Terminal ===")
        print(f"Mod√®le actuel: {self.model}")
        print("Tapez votre demande ou '!help' pour les commandes disponibles.")
        
        # Contexte pour la conversation
        conversation_context = None
        system_info = self.get_system_info()
        
        while True:
            try:
                user_input = input("\nüîç Que voulez-vous faire ? (ou '!exit' pour quitter) : ").strip()
                
                # Commandes sp√©ciales
                if not user_input:
                    continue
                
                if user_input.lower() in ("!exit", "!quit", "exit", "quit"):
                    print("Au revoir!")
                    break
                
                if user_input.lower() == "!help":
                    print("\nCommandes disponibles:")
                    print("  !info    - Afficher les informations syst√®me")
                    print("  !model   - Afficher le mod√®le actuel")
                    print("  !model <nom> - Changer de mod√®le")
                    print("  !history - Afficher l'historique des commandes")
                    print("  !exec <commande> - Ex√©cuter directement une commande shell")
                    print("  !context - R√©initialiser le contexte de conversation")
                    print("  !exit    - Quitter le programme")
                    continue
                
                if user_input.lower() == "!info":
                    self.show_info()
                    continue
                
                if user_input.lower() == "!history":
                    self.show_history()
                    continue
                
                if user_input.lower().startswith("!model"):
                    parts = user_input.split(maxsplit=1)
                    model_name = parts[1] if len(parts) > 1 else ""
                    self.change_model(model_name)
                    continue
                
                if user_input.lower() == "!context":
                    conversation_context = None
                    print("Contexte de conversation r√©initialis√©.")
                    continue
                
                if user_input.lower().startswith("!exec "):
                    command = user_input[6:].strip()
                    if command:
                        self.exec_direct_command(command)
                    continue
                
                # Assurer que le serveur est en cours d'ex√©cution
                if not self._ensure_server_running():
                    continue
                
                # Assurer que le mod√®le est disponible
                if not self._ensure_model_available():
                    continue
                
                # Traitement des demandes normales
                prompt = (
                    f"Je suis un assistant IA sur {system_info}. "
                    f"Donne-moi une ou plusieurs commandes bash pr√©cises "
                    f"pour accomplir cette t√¢che : '{user_input}'. Ne donne que les lignes de commande valides, "
                    f"sans explication, sans bloc markdown, sans guillemets, ni num√©rotation."
                )
                
                command_output, new_context = self.ask_ollama(prompt, conversation_context)
                
                # Mettre √† jour le contexte si disponible
                if new_context:
                    conversation_context = new_context
                
                if not command_output:
                    print("Aucune commande sugg√©r√©e.")
                    continue
                
                print("\n=== Commande(s) sugg√©r√©e(s) ===")
                print(command_output)
                
                # Nettoyer et extraire les commandes
                commands = self.clean_command_output(command_output)
                
                if not commands:
                    print("Aucune commande valide n'a √©t√© extraite.")
                    continue
                
                # S√©lection et ex√©cution des commandes
                selected_commands = self.select_commands(commands)
                
                if selected_commands:
                    print("\n=== Ex√©cution en cours ===")
                    for cmd in selected_commands:
                        # Enregistrer la commande dans l'historique
                        self._save_history(cmd)
                        # Ex√©cuter la commande
                        self.run_shell_command(cmd)
                else:
                    print("Aucune commande n'a √©t√© ex√©cut√©e.")
                    
            except KeyboardInterrupt:
                print("\nOp√©ration annul√©e.")
            except Exception as e:
                print(f"Erreur inattendue: {e}")


if __name__ == "__main__":
    terminal = OllamaTerminal()
    terminal.main()